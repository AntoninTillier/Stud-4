{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pytube"
      ],
      "metadata": {
        "id": "oBimGeHzDpCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Upload video file**"
      ],
      "metadata": {
        "id": "f89X1lpSuUNa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FwRGMD57pXwG",
        "outputId": "473fc7a1-8fdb-43d1-fe36-4b05dddc008d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/THE FRENCH DISPATCH  Official Trailer  Searchlight Pictures.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from pytube import YouTube\n",
        "\n",
        "url = \"https://www.youtube.com/watch?v=TcPk2p0Zaw4\"\n",
        "# Create a YouTube object\n",
        "yt = YouTube(url)\n",
        "# Get the highest resolution stream (you can change this as needed)\n",
        "video_stream = yt.streams.get_highest_resolution()\n",
        "# Download the video to the current directory\n",
        "video_stream.download()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys, re, glob\n",
        "\n",
        "dir = '/content/'\n",
        "file_extention_type = '.mp4'\n",
        "video_glob = glob.glob(dir + '/*' + file_extention_type)\n",
        "video_glob = [video for video in glob.glob(dir + '/*' + file_extention_type) if not \"FILTER_OPTIONS\" in video]\n",
        "\n",
        "for video in video_glob:\n",
        "  print(video)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtWKoODXEBLX",
        "outputId": "6c1cfbd8-81c4-4f36-b98b-b7ed269ddcb2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/THE FRENCH DISPATCH  Official Trailer  Searchlight Pictures.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercice 1: Getting Started with Python + OpenCV**"
      ],
      "metadata": {
        "id": "E8VUu-YGuTtu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code a video processing"
      ],
      "metadata": {
        "id": "otoawo56_zQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import time\n",
        "import base64\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "cap = cv2.VideoCapture(video_glob[0])\n",
        "\n",
        "# Function to display images with HTML\n",
        "def display_images(frame, img):\n",
        "    display(HTML(\n",
        "        f'<div style=\"display: flex; justify-content: center;\">'\n",
        "        f'<div style=\"flex: 50%; padding: 10px;\">'\n",
        "        f'<img src=\"data:image/jpeg;base64,{base64.b64encode(cv2.imencode(\".jpg\", frame)[1]).decode()}\" width=\"100%\"/>'\n",
        "        f'</div>'\n",
        "        f'<div style=\"flex: 50%; padding: 10px;\">'\n",
        "        f'<img src=\"data:image/jpeg;base64,{base64.b64encode(cv2.imencode(\".jpg\", img)[1]).decode()}\" width=\"100%\"/>'\n",
        "        f'</div>'\n",
        "        f'</div>'\n",
        "    ))\n",
        "\n",
        "i = 0\n",
        "while True:\n",
        "    # Read a frame from the video\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    # Create a modified frame\n",
        "    img = frame.copy()\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    # Display the frames\n",
        "    print(i)\n",
        "    clear_output(wait=True)\n",
        "    display_images(frame, gray)\n",
        "    time.sleep(0.1)\n",
        "    i += 1\n",
        "    if i > 57 :\n",
        "      base = frame.copy()\n",
        "      break\n",
        "cap.release()"
      ],
      "metadata": {
        "id": "nVJDV37SuhTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(base)"
      ],
      "metadata": {
        "id": "tVAHk8-iOjyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_images_around_base(base_image_path, images_paths, titles=None):\n",
        "    # Define the number of rows and columns for the table\n",
        "    num_rows = len(images_paths)//2+len(images_paths)%2\n",
        "    num_cols = 2\n",
        "    # Create an HTML table to arrange the images\n",
        "    html_table = '<table style=\"width:100%\">'\n",
        "    # Add the base image to the table\n",
        "    html_table += f'<td colspan=\"4\"><img src=\"data:image/jpeg;base64,{base64.b64encode(cv2.imencode(\".jpg\", base_image_path)[1]).decode()}\" width=\"100%\"></td>'\n",
        "    html_table += '</tr>'\n",
        "    html_table += '<tr><td colspan=\"4\" style=\"text-align:center;\">Base Image</td></tr>'\n",
        "    html_table += '<tr>'\n",
        "    if images_paths:\n",
        "        # Add images around the base image\n",
        "          for i in range(num_rows):\n",
        "              html_table += '<tr>'\n",
        "              for j in range(num_cols):\n",
        "                  try:\n",
        "                    index = i * num_cols + j\n",
        "                    image_path = images_paths[index]\n",
        "                    if titles:\n",
        "                        html_table += f'<td style=\"text-align:center;\">{titles[index]}</td>'\n",
        "                    html_table += f'<td><img src=\"data:image/jpeg;base64,{base64.b64encode(cv2.imencode(\".jpg\", image_path)[1]).decode()}\" width=\"100%\"></td>'\n",
        "                  except IndexError:\n",
        "                    break\n",
        "              html_table += '</tr>'\n",
        "    html_table += '</table>'\n",
        "    # Display the HTML table\n",
        "    display(HTML(html_table))"
      ],
      "metadata": {
        "id": "rp8thQANSmpk"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 2: Filtering, Convolution, Edge Detection**"
      ],
      "metadata": {
        "id": "ESUySNuSztAO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply various filtering treatments to the current frame before display"
      ],
      "metadata": {
        "id": "LlyggbjlRLIF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Blur"
      ],
      "metadata": {
        "id": "yvY5bY-KQRmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = cv2.blur (base ,(5 ,5))"
      ],
      "metadata": {
        "id": "fxIwZR1FQTIL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Median blur"
      ],
      "metadata": {
        "id": "WwlRqrElQTYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mb = cv2.medianBlur(base ,9)"
      ],
      "metadata": {
        "id": "vikcNED6QXip"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gaussian blur"
      ],
      "metadata": {
        "id": "z599X2hCQXtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gb = cv2.GaussianBlur(base ,(5,5) ,1.6)"
      ],
      "metadata": {
        "id": "tNKKEWfjQZoa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolution"
      ],
      "metadata": {
        "id": "mwkpo-JnQZ3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel = np.ones((5,5),np.float32)/25\n",
        "conv = cv2.filter2D(base,-1,kernel)"
      ],
      "metadata": {
        "id": "2g14vZT1Qg4E"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_images_around_base(base, [b, mb, gb, conv], ['blur', 'median blur', 'gaussian blur', 'convolution'])"
      ],
      "metadata": {
        "id": "Fwn8_ALmROFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply various contour detection algorithms."
      ],
      "metadata": {
        "id": "namvwjF5cgpv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Laplacian"
      ],
      "metadata": {
        "id": "OoeP7G4icqec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lap = cv2.Laplacian(base,cv2.CV_64F)"
      ],
      "metadata": {
        "id": "CBGSO6YmcqyL"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sobel x"
      ],
      "metadata": {
        "id": "dCioEHgGcrBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sx = cv2.Sobel(base,cv2.CV_64F,1,0,ksize=5)"
      ],
      "metadata": {
        "id": "0dcujK_scrYe"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sobel y"
      ],
      "metadata": {
        "id": "37oUBSRIc0Ta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sy = cv2.Sobel(base,cv2.CV_64F,0,1,ksize=5)"
      ],
      "metadata": {
        "id": "yj93KU7pc1B0"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Canny"
      ],
      "metadata": {
        "id": "XukXRImDc1T0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c = cv2.Canny(base ,50,100)"
      ],
      "metadata": {
        "id": "ZZP3x870dEgl"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_images_around_base(base, [lap, sx, sy, c], ['laplacian', 'sobel x', 'sobel y', 'canny'])"
      ],
      "metadata": {
        "id": "l5oqzozKdOA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 3: Binary Images and Image Operations**"
      ],
      "metadata": {
        "id": "DYgdSWded1E3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply different thresholding/binarization algorithms (fixed or adaptive thresholding) followed by mathematical morphology operations (erosion, dilation) to the current frame before display"
      ],
      "metadata": {
        "id": "vzlorDhfd1aX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "thresholding/binarization"
      ],
      "metadata": {
        "id": "tIABXc_peIB0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Binary"
      ],
      "metadata": {
        "id": "y1Po3lICeO1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ret , b = cv2.threshold(base, 127, 255, cv2.THRESH_BINARY)"
      ],
      "metadata": {
        "id": "Ji5MTOVid1sD"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inverse binary"
      ],
      "metadata": {
        "id": "5foLmqPpeWcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ret , ib = cv2.threshold(base, 127, 255, cv2.THRESH_BINARY_INV)"
      ],
      "metadata": {
        "id": "cTuJr7HaeWxg"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trunc"
      ],
      "metadata": {
        "id": "fFd-r4OhebLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ret, t = cv2.threshold(base, 127, 255, cv2.THRESH_TRUNC)"
      ],
      "metadata": {
        "id": "cMro744febel"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To zero"
      ],
      "metadata": {
        "id": "6AXJr6gUegGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ret, z = cv2.threshold(base, 127, 255, cv2.THRESH_TOZERO)"
      ],
      "metadata": {
        "id": "wDhFkAS6egco"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inverse to zero"
      ],
      "metadata": {
        "id": "m6ndiL1SehTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ret, iz = cv2.threshold(base, 127, 255, cv2.THRESH_TOZERO_INV)"
      ],
      "metadata": {
        "id": "Lg9iLfZXehnx"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_images_around_base(base, [b, ib, t, z, iz], ['binary', 'inverse binary', 'trunc', 'to zero', 'inverse to zero'])"
      ],
      "metadata": {
        "id": "kIQTsLYqgFI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "mathematical morphology"
      ],
      "metadata": {
        "id": "Tw9VOK70eI0N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dilate"
      ],
      "metadata": {
        "id": "TAwgZi-9fARb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = cv2.dilate(base, kernel,iterations = 1)"
      ],
      "metadata": {
        "id": "99yeWI32eOSB"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Erode"
      ],
      "metadata": {
        "id": "9FjF6TMsfBUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "e = cv2.erode(base,kernel,iterations = 1)"
      ],
      "metadata": {
        "id": "Z5iqOKX9fBkJ"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Morphology open"
      ],
      "metadata": {
        "id": "zlS5FtfAfDx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mo = cv2.morphologyEx(base, cv2.MORPH_OPEN, kernel)"
      ],
      "metadata": {
        "id": "6sxKKOp6fED0"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Morphology close"
      ],
      "metadata": {
        "id": "19xAVapffNWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mc = cv2.morphologyEx(base, cv2.MORPH_CLOSE, kernel)"
      ],
      "metadata": {
        "id": "cZpbn23wfNnY"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Morphology gradient"
      ],
      "metadata": {
        "id": "xnDEC5CWfQSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mg = cv2.morphologyEx(base, cv2.MORPH_GRADIENT, kernel)"
      ],
      "metadata": {
        "id": "wn2Zaq8pfQh6"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Morphology top hat"
      ],
      "metadata": {
        "id": "P_F0Qz6YfVJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tophat = cv2.morphologyEx(base, cv2.MORPH_TOPHAT, kernel)"
      ],
      "metadata": {
        "id": "4VQRJ3I2fVXt"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Morphology balck hat"
      ],
      "metadata": {
        "id": "hjXNJGFefnLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "blackhat = cv2.morphologyEx(base, cv2.MORPH_BLACKHAT, kernel)"
      ],
      "metadata": {
        "id": "j2PeWMcSfnff"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_images_around_base(base, [d, e, mo, mc, mg, tophat, blackhat], ['dilate', 'erode', 'morphology open', 'morphology close', 'morphology gradient', 'morphology top hat', 'morphology balck hat'])"
      ],
      "metadata": {
        "id": "FZp368UcgDpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 4: Shot Change Detection and Automatic Video Summarization**"
      ],
      "metadata": {
        "id": "qSrIWOnjjj4x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement an automatic shot change detection mechanism in a video"
      ],
      "metadata": {
        "id": "EFvcBOL-kkNE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Difference of more than 15%"
      ],
      "metadata": {
        "id": "aHEnTVVXlcPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(video_glob[0])\n",
        "ret, before = cap.read()\n",
        "counter , i = 0, 0\n",
        "while True:\n",
        "    # Read a frame from the video\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    res = cv2.absdiff(frame, before)\n",
        "    res = res.astype(np.uint8)\n",
        "    # find percentage difference based on number of pixels that are not zero\n",
        "    percentage = (np.count_nonzero(res) * 100) / res.size\n",
        "    # difference of more than 15% with frame\n",
        "    if percentage >= 15:\n",
        "      counter += 1\n",
        "      before = frame\n",
        "      print(\"index =>\", i, \"----------shot change---------------==>\", counter)\n",
        "    i += 1\n",
        "    if i > 100 :\n",
        "      break\n",
        "cap.release()"
      ],
      "metadata": {
        "id": "hO-9WhoTkpuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement an automatic mechanism for generating scene summaries in videos"
      ],
      "metadata": {
        "id": "hNN8Dnc2onN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(video_glob[0])\n",
        "ret, before = cap.read()\n",
        "img_list = []\n",
        "counter , i = 0, 0\n",
        "while True:\n",
        "    # Read a frame from the video\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    res = cv2.absdiff(frame, before)\n",
        "    res = res.astype(np.uint8)\n",
        "    img_list.append(frame)\n",
        "    # find percentage difference based on number of pixels that are not zero\n",
        "    percentage = (np.count_nonzero(res) * 100) / res.size\n",
        "    # difference of more than 15% with frame\n",
        "    if percentage >= 15:\n",
        "      counter += 1\n",
        "      before = frame\n",
        "      print(\"index =>\", i, \"----------shot change---------------==>\", counter, \" number of frames in the previous scene=>\", len(img_list))\n",
        "      img_list.clear()\n",
        "    i += 1\n",
        "    if i > 100 :\n",
        "      break\n",
        "cap.release()"
      ],
      "metadata": {
        "id": "iKC4jKAvot2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 5: SIFT Descriptor Calculation, Descriptor Matching, and Automatic Video Summarization**"
      ],
      "metadata": {
        "id": "GEr43wAYqTV3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating SIFT descriptors and matching"
      ],
      "metadata": {
        "id": "ExZhQ5S0vx49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_sift_matches(img1, img2, threshold=0.7):\n",
        "    img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "    img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "    # Initialize the SIFT detector\n",
        "    sift = cv2.SIFT_create()\n",
        "    # Detect keypoints and compute descriptors\n",
        "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
        "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
        "    # Create a Brute Force Matcher object\n",
        "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
        "    # Match descriptors\n",
        "    matches = bf.match(des1, des2)\n",
        "    # Apply ratio test\n",
        "    good_matches = 0\n",
        "    for m in matches:\n",
        "        if m.distance < threshold:\n",
        "            good_matches += 1\n",
        "    return good_matches"
      ],
      "metadata": {
        "id": "nnENfJUJwLd6"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding the best match"
      ],
      "metadata": {
        "id": "C63YadXtxI_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_best_matching_image(sequence):\n",
        "    best_match_idx = -1\n",
        "    best_num_matches = 0\n",
        "    for i in range(1, len(sequence)):\n",
        "        img1 = sequence[i - 1]\n",
        "        img2 = sequence[i]\n",
        "        # Calculate SIFT matches between the two images\n",
        "        num_matches = find_sift_matches(img1, img2)\n",
        "        if num_matches > best_num_matches:\n",
        "            best_num_matches = num_matches\n",
        "            best_match_idx = i\n",
        "    if best_match_idx != -1:\n",
        "        return sequence[best_match_idx]\n",
        "    return None"
      ],
      "metadata": {
        "id": "nAH2QOc8xJVU"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating scene summary images"
      ],
      "metadata": {
        "id": "HQrVcjxWwU0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(video_glob[0])\n",
        "ret, before = cap.read()\n",
        "img_list = [before]\n",
        "counter , i = 0, 0\n",
        "while True:\n",
        "    # Read a frame from the video\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    img_list.append(frame)\n",
        "    bmi = find_best_matching_image(img_list)\n",
        "    if bmi is not None:\n",
        "      counter += 1\n",
        "      print(\"index =>\", i, \"----------shot change---------------==>\", counter, \" number of frames in the previous scene=>\", len(img_list))\n",
        "      img_list.clear()\n",
        "      ret, before = cap.read()\n",
        "      img_list.append(before)\n",
        "    i += 1\n",
        "    if i > 100 :\n",
        "      break\n",
        "cap.release()"
      ],
      "metadata": {
        "id": "GfpDAWpqzbaQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}